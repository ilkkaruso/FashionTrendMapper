---
phase: 02-data-collection
plan: 04
type: execute
wave: 2
depends_on: ["02-01", "02-02", "02-03"]
files_modified:
  - lib/normalizers/score-normalizer.ts
  - lib/database/trend-repository.ts
autonomous: true

must_haves:
  truths:
    - "Scores from different sources normalized to 0-100 scale"
    - "Trends from multiple sources aggregated by title"
    - "Trends saved to database with source breakdown"
    - "Historical snapshots created for change tracking"
  artifacts:
    - path: "lib/normalizers/score-normalizer.ts"
      provides: "Score normalization and aggregation"
      exports: ["normalizeScores", "aggregateTrends"]
    - path: "lib/database/trend-repository.ts"
      provides: "Database operations for trends"
      exports: ["saveTrendsWithHistory", "getTrendsWithChange"]
  key_links:
    - from: "lib/normalizers/score-normalizer.ts"
      to: "lib/fetchers/types.ts"
      via: "RawTrend, NormalizedTrend types"
      pattern: "RawTrend|NormalizedTrend"
    - from: "lib/database/trend-repository.ts"
      to: "lib/supabase/server.ts"
      via: "createClient()"
      pattern: "createClient"
    - from: "lib/database/trend-repository.ts"
      to: "supabase.from('trends')"
      via: "upsert operations"
      pattern: "from\\('trends'\\)"
---

<objective>
Create score normalization and database persistence layer.

Purpose: Normalize scores from Google (0-100 scale) and Reddit (0-10000+ upvotes) to consistent 0-100 scale. Aggregate trends by title and save to Supabase with history tracking for change calculations.
Output: Normalizer that produces consistent scores and repository that persists trends with history.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-data-collection/02-RESEARCH.md
@lib/fetchers/types.ts
@lib/supabase/server.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create score normalizer</name>
  <files>lib/normalizers/score-normalizer.ts</files>
  <action>
Create `lib/normalizers/score-normalizer.ts`:

Import types from `@/lib/fetchers/types`.

Create `normalizeScores(trends: RawTrend[]): NormalizedTrend[]`:

1. Separate trends by source:
   ```typescript
   const googleTrends = trends.filter(t => t.source === 'google');
   const redditTrends = trends.filter(t => t.source === 'reddit');
   ```

2. Google Trends are already 0-100 scale (search volume), but parse traffic strings:
   - "50K+" -> normalize relative to max in batch
   - Keep original if already numeric

3. Reddit trends need min-max normalization:
   ```typescript
   function minMaxNormalize(values: number[]): number[] {
     const min = Math.min(...values);
     const max = Math.max(...values);
     if (max === min) return values.map(() => 50); // All equal = 50
     return values.map(v => ((v - min) / (max - min)) * 100);
   }
   ```

4. Map each trend to NormalizedTrend:
   ```typescript
   {
     title: trend.title,
     score: normalizedScore, // 0-100
     sources: [trend.source],
     sourceBreakdown: {
       [trend.source]: normalizedScore
     },
     metadata: trend.metadata
   }
   ```

5. Return array of NormalizedTrend[]

Create `aggregateTrends(trends: NormalizedTrend[]): NormalizedTrend[]`:

1. Group trends by title (case-insensitive, trimmed)
2. For each group:
   - Merge sources arrays
   - Merge sourceBreakdown objects
   - Calculate weighted average score:
     - Google weight: 0.6 (more reliable, search data)
     - Reddit weight: 0.4 (community sentiment)
     - If only one source, use that score
   ```typescript
   const weights = { google: 0.6, reddit: 0.4 };
   const weightedSum = sources.reduce((sum, source) => {
     return sum + (sourceBreakdown[source] * weights[source]);
   }, 0);
   const totalWeight = sources.reduce((sum, source) => sum + weights[source], 0);
   const score = weightedSum / totalWeight;
   ```
3. Return deduplicated, aggregated NormalizedTrend[]

Export both functions.
  </action>
  <verify>
`npx tsc --noEmit` passes.
Unit test (manual): normalizeScores([{score: 1000, source: 'reddit'}, {score: 100, source: 'reddit'}]) returns [100, 10] approximately.
  </verify>
  <done>
Score normalizer exports normalizeScores and aggregateTrends.
Reddit upvotes scaled to 0-100 via min-max.
Aggregation uses 60/40 Google/Reddit weighting.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create trend repository</name>
  <files>lib/database/trend-repository.ts</files>
  <action>
Create `lib/database/trend-repository.ts`:

Import createClient from `@/lib/supabase/server`.
Import types from `@/lib/fetchers/types`.

Create `saveTrendsWithHistory(trends: NormalizedTrend[]): Promise<void>`:

1. Get Supabase client
2. Get today's date string: `new Date().toISOString().split('T')[0]`
3. For each trend:
   a. Upsert to `trends` table:
      ```typescript
      const { data: trendData, error } = await supabase
        .from('trends')
        .upsert({
          title: trend.title,
          description: null, // Will be enriched later
          current_score: trend.score,
          updated_at: new Date().toISOString(),
        }, {
          onConflict: 'title',
        })
        .select('id')
        .single();
      ```
   b. If trend exists, update its score. If new, insert.

   c. Upsert to `trend_sources` for each source:
      ```typescript
      for (const source of trend.sources) {
        await supabase
          .from('trend_sources')
          .upsert({
            trend_id: trendData.id,
            source_name: source,
            source_score: trend.sourceBreakdown[source] || 0,
            fetched_at: new Date().toISOString(),
          }, {
            onConflict: 'trend_id,source_name',
          });
      }
      ```

   d. Upsert to `trend_history` for daily snapshot:
      ```typescript
      await supabase
        .from('trend_history')
        .upsert({
          trend_id: trendData.id,
          snapshot_date: today,
          data_snapshot: {
            score: trend.score,
            sources: trend.sources,
            sourceBreakdown: trend.sourceBreakdown,
          },
        }, {
          onConflict: 'trend_id,snapshot_date',
        });
      ```

4. Log success count or errors

Create `getTrendsWithChange(): Promise<TrendWithHistory[]>`:

1. Get today and yesterday date strings
2. Fetch all trends with their history:
   ```typescript
   const { data } = await supabase
     .from('trends')
     .select(`
       id,
       title,
       current_score,
       trend_history!inner (
         snapshot_date,
         data_snapshot
       )
     `)
     .order('current_score', { ascending: false });
   ```
3. For each trend, calculate change:
   - Find yesterday's snapshot
   - If exists: change = current_score - yesterday_score
   - If not exists: change = null (new trend)
4. Return TrendWithHistory[] sorted by score

Handle errors gracefully - log and throw descriptive errors.
  </action>
  <verify>
`npx tsc --noEmit` passes.
Functions match expected signatures in types.ts.
  </verify>
  <done>
Trend repository exports saveTrendsWithHistory and getTrendsWithChange.
Upserts trends, sources, and history to Supabase.
Calculates daily change percentage from history.
  </done>
</task>

</tasks>

<verification>
1. TypeScript compiles: `npm run build`
2. Normalizer handles edge cases (empty array, single item, all same score)
3. Repository functions have proper Supabase client usage
4. History tracking uses correct date format for snapshot_date
</verification>

<success_criteria>
- [ ] lib/normalizers/score-normalizer.ts exports normalizeScores, aggregateTrends
- [ ] Min-max normalization scales Reddit 0-10000+ to 0-100
- [ ] Aggregation uses 60/40 Google/Reddit weighting
- [ ] lib/database/trend-repository.ts exports saveTrendsWithHistory, getTrendsWithChange
- [ ] Trends upserted by title (no duplicates)
- [ ] Source scores saved to trend_sources table
- [ ] Daily snapshots saved to trend_history table
- [ ] Change calculation compares today vs yesterday
- [ ] TypeScript compilation passes
</success_criteria>

<output>
After completion, create `.planning/phases/02-data-collection/02-04-SUMMARY.md`
</output>
